# Model configuration (from param tuning)
model:
  hidden_dim: 64
  num_layers: 3
  aggregator: max
  dropout: 0.1

training:
  learning_rate: 0.001
  batch_size: 512
  num_epochs: 150
  early_stopping_patience: 12
  early_stopping_min_delta: 0.0001
  loss_type: mse
